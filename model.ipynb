{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826dfd61",
   "metadata": {},
   "source": [
    "# AI-Generated Image Detection using CNN\n",
    "\n",
    "This notebook implements a Convolutional Neural Network (CNN) to classify images as **Real** or **AI-Generated (Fake)**. \n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Model Architecture**: A custom CNN with 3 convolutional blocks for feature extraction\n",
    "2. **Data Pipeline**: Loading, preprocessing, and augmentation of images\n",
    "3. **Training Loop**: Complete training with validation and model checkpointing\n",
    "4. **Evaluation**: Performance metrics including Accuracy, Precision, Recall, and F1-Score\n",
    "\n",
    "## Dataset Structure\n",
    "\n",
    "The dataset should be organized in the following folder structure:\n",
    "```\n",
    "archive/\n",
    "├── FAKE/    # AI-generated images\n",
    "└── REAL/    # Real photographs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d163c2",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "Import all necessary libraries for deep learning, data handling, and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4399003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48c25f",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Define hyperparameters and settings for the model training. These can be adjusted to experiment with different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = 'archive'\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Specific device selection: Use GPU (cuda) if available for faster training, otherwise fallback to CPU.\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c491d8",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "The CNN architecture consists of:\n",
    "- **3 Convolutional Blocks**: Each block contains Conv2D → BatchNorm → ReLU → MaxPool\n",
    "- **Fully Connected Layers**: For classification after feature extraction\n",
    "- **Dropout**: To prevent overfitting\n",
    "\n",
    "### Architecture Details\n",
    "\n",
    "| Layer | Input Size | Output Size | Description |\n",
    "|-------|------------|-------------|-------------|\n",
    "| Conv1 | 128×128×3 | 128×128×32 | Extract low-level features |\n",
    "| Pool1 | 128×128×32 | 64×64×32 | Reduce spatial dimensions |\n",
    "| Conv2 | 64×64×32 | 64×64×64 | Extract mid-level features |\n",
    "| Pool2 | 64×64×64 | 32×32×64 | Reduce spatial dimensions |\n",
    "| Conv3 | 32×32×64 | 32×32×128 | Extract high-level features |\n",
    "| Pool3 | 32×32×128 | 16×16×128 | Reduce spatial dimensions |\n",
    "| FC1 | 32768 | 512 | Classification layer |\n",
    "| FC2 | 512 | 1 | Output (logit) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8663b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIImageDetectorCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Neural Network (CNN) for binary image classification (Real vs Fake).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(AIImageDetectorCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers (Feature Extraction)\n",
    "        # We assume input images are resized to 128x128 pixels with 3 color channels (RGB).\n",
    "        # Input Shape: [Batch_Size, 3, 128, 128]\n",
    "        \n",
    "        # Layer 1: \n",
    "        # Conv2d: Extracts low-level features (edges, colors).\n",
    "        # out_channels=32: Creates 32 different feature maps.\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        # BatchNorm2d: Normalizes the output of the convolution. \n",
    "        # Helps training stability and speed by keeping activation distributions consistent.\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Layer 2:\n",
    "        # Increases depth to 64 channels to capture more complex textures/patterns.\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Layer 3:\n",
    "        # Increases depth to 128 channels for high-level feature abstraction.\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Pooling Layer: \n",
    "        # MaxPool2d reduces spatial dimensions (height/width) by half (stride=2).\n",
    "        # This reduces computation and makes the model translation invariant (robust to position shifts).\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Dropout: \n",
    "        # Randomly zeros out 50% of neurons during training.\n",
    "        # Prevents overfitting by forcing the network to learn redundant representations.\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Fully Connected Layers (Classification)\n",
    "        # Calculate Flattened Input Size:\n",
    "        # Original Image: 128x128\n",
    "        # After Pool 1: 64x64\n",
    "        # After Pool 2: 32x32\n",
    "        # After Pool 3: 16x16\n",
    "        # Final Tensor Shape before flattening: [Batch_Size, 128 (channels), 16, 16]\n",
    "        # Flattened Vector Size = 128 * 16 * 16 = 32768\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        \n",
    "        # Output Layer: \n",
    "        # Maps the 512 features to a single value (logit).\n",
    "        # A positive value suggests one class (e.g., Real), negative suggests the other (Fake).\n",
    "        self.fc2 = nn.Linear(512, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass (data flow) of the network.\n",
    "        Args:\n",
    "            x: Input batch of images.\n",
    "        Returns:\n",
    "            x: Unnormalized output scores (logits).\n",
    "        \"\"\"\n",
    "        \n",
    "        # Block 1: Conv -> BN -> ReLU -> Pool\n",
    "        # ReLU (Rectified Linear Unit) introduces non-linearity, allowing the model to learn complex functions.\n",
    "        # without ReLU, the model would just be a linear regression.\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        # Block 2\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Block 3\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Flattening:\n",
    "        # Reshapes the 3D feature maps (Channels, Height, Width) into a 1D vector\n",
    "        # so it can be fed into the Fully Connected (Dense) layers.\n",
    "        # x.size(0) preserves the batch size. -1 infers the remaining dimension size.\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Classification Head:\n",
    "        # FC1 -> ReLU -> Dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        \n",
    "        # Final Output (Logit)\n",
    "        # We do NOT apply Sigmoid here because we use BCEWithLogitsLoss during training,\n",
    "        # which applies Sigmoid internally for better numerical stability.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47c83b",
   "metadata": {},
   "source": [
    "## 4. Data Loading and Preprocessing\n",
    "\n",
    "The data pipeline includes:\n",
    "- **Resize**: All images are resized to 128×128 pixels\n",
    "- **ToTensor**: Converts PIL images (0-255) to PyTorch tensors (0-1)\n",
    "- **Normalize**: Standardizes pixel values using ImageNet statistics for better convergence\n",
    "\n",
    "The dataset is split into **80% training** and **20% validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344fffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(data_dir, batch_size, img_size):\n",
    "    \"\"\"\n",
    "    Prepares the training and validation data loaders.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Path to the dataset directory.\n",
    "        batch_size (int): Number of images per batch.\n",
    "        img_size (int): Target size to resize images.\n",
    "        \n",
    "    Returns:\n",
    "        train_loader: DataLoader for training data.\n",
    "        val_loader: DataLoader for validation data.\n",
    "        class_to_idx: Dictionary mapping class names to indices.\n",
    "    \"\"\"\n",
    "    # Data augmentation and normalization for training\n",
    "    # - Resize: Ensures all images are the same size for the neural network input.\n",
    "    # - ToTensor: Converts PIL images (0-255) to PyTorch tensors (0-1).\n",
    "    # - Normalize: Standardizes pixel values to resemble ImageNet statistics (mean ~0, std ~1).\n",
    "    #   This helps the model converge (learn) faster and reach a stable solution.\n",
    "    #   Values (0.485, ...) are standard constants for pre-trained models/general natural images gathered from the internet.\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Load dataset from folder structure (folder name = class label)\n",
    "    try:\n",
    "        full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data directory '{data_dir}' not found.\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Split into train and validation (80/20)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    print(f\"Dataset loaded. Classes: {full_dataset.classes}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "    # DataLoader handles batching, shuffling, and parallel data loading (num_workers).\n",
    "    # Shuffle=True for training prevents the model from learning order-based patterns.\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader, val_loader, full_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2227a1",
   "metadata": {},
   "source": [
    "## 5. Evaluation Function\n",
    "\n",
    "This function calculates key classification metrics:\n",
    "- **Accuracy**: Overall correct predictions\n",
    "- **Precision**: True positives / (True positives + False positives)\n",
    "- **Recall**: True positives / (True positives + False negatives)\n",
    "- **F1-Score**: Harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model's performance on a given dataset (validation/test).\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode.\n",
    "    # Disables Dropout and switches BatchNorm to use running statistics.\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # torch.no_grad() disables gradient calculation.\n",
    "    # We don't need gradients for evaluation, and this saves memory and computation.\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).float()\n",
    "            \n",
    "            # Move results back to CPU and convert to numpy for scikit-learn metrics\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    # Calculate metrics using scikit-learn\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    \n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a292f4",
   "metadata": {},
   "source": [
    "## 6. Training Function\n",
    "\n",
    "The training loop implements:\n",
    "- **Forward pass**: Compute predictions\n",
    "- **Loss calculation**: Using Binary Cross-Entropy with Logits\n",
    "- **Backward pass**: Compute gradients via backpropagation\n",
    "- **Optimizer step**: Update model weights\n",
    "- **Model checkpointing**: Save the best model based on validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e4ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    \"\"\"\n",
    "    Executes the training loop.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model.\n",
    "        train_loader: DataLoader for training data.\n",
    "        val_loader: DataLoader for validation data.\n",
    "        criterion: Loss function (BCEWithLogitsLoss).\n",
    "        optimizer: Optimization algorithm (Adam).\n",
    "        num_epochs: Number of times to iterate over the entire dataset.\n",
    "        device: 'cuda' or 'cpu'.\n",
    "    \"\"\"\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    print(f\"Starting training on {device}...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Set model to training mode. \n",
    "        # This enables layers like Dropout and BatchNorm that behave differently during training vs inference.\n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        # tqdm creates a visual progress bar for the epoch loop (wraps around the DataLoader)\n",
    "        loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        \n",
    "        for inputs, labels in loop:\n",
    "            # Move data to the configured device (GPU/CPU) for computation\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients.\n",
    "            # PyTorch accumulates gradients by default. We must clear them before the backward pass\n",
    "            # of this batch, otherwise gradients from previous batches would mix in.\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward Pass: Compute predicted outputs by passing inputs to the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Prepare labels for Loss Calculation\n",
    "            # BCEWithLogitsLoss expects labels to be Float tensors.\n",
    "            # .unsqueeze(1) reshapes labels from [batch_size] to [batch_size, 1] to match the shape of the model output.\n",
    "            labels = labels.float().unsqueeze(1) \n",
    "            \n",
    "            # Calculate Loss: Determine how wrong the model's predictions are compared to actual labels\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward Pass (Backpropagation):\n",
    "            # Calculates the gradient of the loss with respect to model parameters.\n",
    "            # It figures out \"direction\" and \"magnitude\" to adjust weights to reduce error.\n",
    "            loss.backward()\n",
    "            \n",
    "            # Optimizer Step:\n",
    "            # Updates the model's weights based on the computed gradients.\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics & Metrics Tracking:\n",
    "            \n",
    "            # Add current batch loss to running total (loss.item() extracts the scalar value)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Convert logits (raw output) to probabilities using Sigmoid (0 to 1 range)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            \n",
    "            # Threshold probabilities to binary predictions (0 or 1)\n",
    "            preds = (probs > 0.5).float()\n",
    "            \n",
    "            # Count correct predictions\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "            \n",
    "            # Update progress bar with current batch loss\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        train_acc = correct_train / total_train\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase: Evaluate model on unseen data\n",
    "        val_acc, val_precision, val_recall, val_f1 = evaluate_model(model, val_loader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} -> \"\n",
    "              f\"Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Save the best model based on validation accuracy.\n",
    "        # This ensures we keep the version of the model that generalized best, \n",
    "        # not necessarily the one from the very last epoch (which might be overfitting).\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(\"Saved best model.\")\n",
    "\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef16494c",
   "metadata": {},
   "source": [
    "## 7. Load and Prepare Data\n",
    "\n",
    "Load the dataset and create data loaders for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_loader, val_loader, class_mapping = get_data_loaders(DATA_DIR, BATCH_SIZE, IMG_SIZE)\n",
    "\n",
    "# Display class mapping\n",
    "print(f\"Class Mapping: {class_mapping}\")  # {'FAKE': 0, 'REAL': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b762d9",
   "metadata": {},
   "source": [
    "## 8. Initialize Model, Loss Function, and Optimizer\n",
    "\n",
    "- **Model**: Custom CNN architecture\n",
    "- **Loss Function**: `BCEWithLogitsLoss` - combines Sigmoid + Binary Cross-Entropy for numerical stability\n",
    "- **Optimizer**: `Adam` - Adaptive Moment Estimation, generally converges faster than SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c374a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and move to device\n",
    "model = AIImageDetectorCNN().to(DEVICE)\n",
    "\n",
    "# BCEWithLogitsLoss combines Sigmoid layer + BCELoss in one class.\n",
    "# This is numerically more stable than using a plain Sigmoid followed by BCELoss.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Adam optimizer: Adaptive Moment Estimation.\n",
    "# Generally performs better and converges faster than SGD for many deep learning tasks.\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Display model summary\n",
    "print(f\"Model moved to: {DEVICE}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb709f",
   "metadata": {},
   "source": [
    "## 9. Train the Model\n",
    "\n",
    "Run the training loop. The best model (based on validation accuracy) will be automatically saved to `best_model.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7196f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b67419",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation\n",
    "\n",
    "Load the best saved model and evaluate its performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best weights saved during training (not necessarily the last epoch's weights)\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate on validation set\n",
    "print(\"--- Final Evaluation on Validation Set ---\")\n",
    "acc, prec, rec, f1 = evaluate_model(model, val_loader, DEVICE)\n",
    "\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
